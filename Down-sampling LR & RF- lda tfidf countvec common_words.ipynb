{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_pickle(\"train_x_features4.pkl\")\n",
    "train_y = pd.read_pickle(\"train_y_features4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['label'] = train_y['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_majority = train_x[train_x.label==0]\n",
    "train_minority = train_x[train_x.label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfidf_cosine        802\n",
       "count_vec_cosine    802\n",
       "lda_cosine          802\n",
       "common_words        802\n",
       "label               802\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_minority.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_0_sample = train_majority.sample(n=802)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled = pd.concat([train_minority, train_0_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_cosine</th>\n",
       "      <th>count_vec_cosine</th>\n",
       "      <th>lda_cosine</th>\n",
       "      <th>common_words</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>0.467912</td>\n",
       "      <td>0.804391</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.750084</td>\n",
       "      <td>0.867254</td>\n",
       "      <td>0.059711</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.698022</td>\n",
       "      <td>0.697114</td>\n",
       "      <td>0.379432</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.445863</td>\n",
       "      <td>0.575562</td>\n",
       "      <td>0.149446</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.627349</td>\n",
       "      <td>0.857040</td>\n",
       "      <td>0.741229</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.491459</td>\n",
       "      <td>0.782361</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.418100</td>\n",
       "      <td>0.752337</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.286552</td>\n",
       "      <td>0.737310</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.544709</td>\n",
       "      <td>0.843250</td>\n",
       "      <td>0.355569</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0.552765</td>\n",
       "      <td>0.675860</td>\n",
       "      <td>0.028352</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.744295</td>\n",
       "      <td>0.805643</td>\n",
       "      <td>0.476418</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.388188</td>\n",
       "      <td>0.613254</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.303346</td>\n",
       "      <td>0.596913</td>\n",
       "      <td>0.017415</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>0.161563</td>\n",
       "      <td>0.730382</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.339268</td>\n",
       "      <td>0.677036</td>\n",
       "      <td>0.078828</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.413952</td>\n",
       "      <td>0.692637</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>0.627688</td>\n",
       "      <td>0.664248</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>0.696794</td>\n",
       "      <td>0.759066</td>\n",
       "      <td>0.580360</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.631585</td>\n",
       "      <td>0.814845</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.355476</td>\n",
       "      <td>0.347321</td>\n",
       "      <td>0.451810</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.390122</td>\n",
       "      <td>0.733016</td>\n",
       "      <td>0.493504</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0.410611</td>\n",
       "      <td>0.778414</td>\n",
       "      <td>0.020495</td>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.208647</td>\n",
       "      <td>0.490329</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0.729485</td>\n",
       "      <td>0.794041</td>\n",
       "      <td>0.109303</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.621541</td>\n",
       "      <td>0.664922</td>\n",
       "      <td>0.614924</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.252483</td>\n",
       "      <td>0.636707</td>\n",
       "      <td>0.024226</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.565020</td>\n",
       "      <td>0.796159</td>\n",
       "      <td>0.030472</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0.600010</td>\n",
       "      <td>0.852563</td>\n",
       "      <td>0.147459</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.785723</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.607163</td>\n",
       "      <td>0.695955</td>\n",
       "      <td>0.455390</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78974</th>\n",
       "      <td>0.089774</td>\n",
       "      <td>0.629203</td>\n",
       "      <td>0.072328</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70641</th>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.411922</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69514</th>\n",
       "      <td>0.385885</td>\n",
       "      <td>0.703737</td>\n",
       "      <td>0.052060</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267712</th>\n",
       "      <td>0.052617</td>\n",
       "      <td>0.567271</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268832</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674467</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83965</th>\n",
       "      <td>0.357156</td>\n",
       "      <td>0.730880</td>\n",
       "      <td>0.617559</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102018</th>\n",
       "      <td>0.074059</td>\n",
       "      <td>0.313646</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130991</th>\n",
       "      <td>0.062790</td>\n",
       "      <td>0.501841</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112156</th>\n",
       "      <td>0.297742</td>\n",
       "      <td>0.748767</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61185</th>\n",
       "      <td>0.065712</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87001</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271225</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150818</th>\n",
       "      <td>0.583780</td>\n",
       "      <td>0.516266</td>\n",
       "      <td>0.780596</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140428</th>\n",
       "      <td>0.054619</td>\n",
       "      <td>0.541163</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170499</th>\n",
       "      <td>0.186032</td>\n",
       "      <td>0.522382</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208436</th>\n",
       "      <td>0.129597</td>\n",
       "      <td>0.714821</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172727</th>\n",
       "      <td>0.238740</td>\n",
       "      <td>0.451421</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225016</th>\n",
       "      <td>0.137721</td>\n",
       "      <td>0.495188</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90046</th>\n",
       "      <td>0.229028</td>\n",
       "      <td>0.722906</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127364</th>\n",
       "      <td>0.218145</td>\n",
       "      <td>0.433622</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>0.066543</td>\n",
       "      <td>0.710387</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117707</th>\n",
       "      <td>0.345045</td>\n",
       "      <td>0.768618</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27306</th>\n",
       "      <td>0.231728</td>\n",
       "      <td>0.606135</td>\n",
       "      <td>0.014165</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117099</th>\n",
       "      <td>0.172651</td>\n",
       "      <td>0.639992</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130878</th>\n",
       "      <td>0.216700</td>\n",
       "      <td>0.552614</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45290</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640666</td>\n",
       "      <td>0.026498</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81422</th>\n",
       "      <td>0.500483</td>\n",
       "      <td>0.721759</td>\n",
       "      <td>0.184850</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150012</th>\n",
       "      <td>0.221304</td>\n",
       "      <td>0.795084</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46046</th>\n",
       "      <td>0.238270</td>\n",
       "      <td>0.719227</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186425</th>\n",
       "      <td>0.238324</td>\n",
       "      <td>0.668139</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61459</th>\n",
       "      <td>0.192873</td>\n",
       "      <td>0.760512</td>\n",
       "      <td>0.199604</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1604 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        tfidf_cosine  count_vec_cosine  lda_cosine  common_words  label\n",
       "1015        0.467912          0.804391    0.000222            50      1\n",
       "392         0.750084          0.867254    0.059711           139      1\n",
       "386         0.698022          0.697114    0.379432            67      1\n",
       "866         0.445863          0.575562    0.149446            40      1\n",
       "786         0.627349          0.857040    0.741229            87      1\n",
       "820         0.491459          0.782361    0.029213           126      1\n",
       "191         0.418100          0.752337    0.000233            50      1\n",
       "209         0.286552          0.737310    0.022934            77      1\n",
       "559         0.544709          0.843250    0.355569            48      1\n",
       "713         0.552765          0.675860    0.028352            48      1\n",
       "399         0.744295          0.805643    0.476418            77      1\n",
       "42          0.388188          0.613254    0.000116            40      1\n",
       "932         0.303346          0.596913    0.017415            66      1\n",
       "1008        0.161563          0.730382    0.000429            17      1\n",
       "93          0.339268          0.677036    0.078828            40      1\n",
       "419         0.413952          0.692637    0.000101            58      1\n",
       "923         0.627688          0.664248    0.015665            24      1\n",
       "968         0.696794          0.759066    0.580360            54      1\n",
       "58          0.631585          0.814845    0.017513           112      1\n",
       "144         0.355476          0.347321    0.451810            20      1\n",
       "48          0.390122          0.733016    0.493504            40      1\n",
       "454         0.410611          0.778414    0.020495           174      1\n",
       "2           0.208647          0.490329    0.001997            17      1\n",
       "836         0.729485          0.794041    0.109303           138      1\n",
       "244         0.621541          0.664922    0.614924            20      1\n",
       "808         0.252483          0.636707    0.024226            41      1\n",
       "459         0.565020          0.796159    0.030472            95      1\n",
       "918         0.600010          0.852563    0.147459           104      1\n",
       "1001        0.474138          0.785723    0.000145            68      1\n",
       "1078        0.607163          0.695955    0.455390            34      1\n",
       "...              ...               ...         ...           ...    ...\n",
       "78974       0.089774          0.629203    0.072328            34      0\n",
       "70641       0.046700          0.411922    0.000551            17      0\n",
       "69514       0.385885          0.703737    0.052060            44      0\n",
       "267712      0.052617          0.567271    0.000899            11      0\n",
       "268832      0.000000          0.674467    0.000604            10      0\n",
       "83965       0.357156          0.730880    0.617559            42      0\n",
       "102018      0.074059          0.313646    0.001591             7      0\n",
       "130991      0.062790          0.501841    0.000587            16      0\n",
       "112156      0.297742          0.748767    0.183100            32      0\n",
       "61185       0.065712          0.512145    0.000769            25      0\n",
       "87001       0.000000          0.271225    0.002247             3      0\n",
       "150818      0.583780          0.516266    0.780596            28      0\n",
       "140428      0.054619          0.541163    0.000688            16      0\n",
       "170499      0.186032          0.522382    0.000188            24      0\n",
       "208436      0.129597          0.714821    0.000408            21      0\n",
       "172727      0.238740          0.451421    0.000565            19      0\n",
       "225016      0.137721          0.495188    0.001210             9      0\n",
       "90046       0.229028          0.722906    0.000310            28      0\n",
       "127364      0.218145          0.433622    0.000793            14      0\n",
       "10664       0.066543          0.710387    0.000135            39      0\n",
       "117707      0.345045          0.768618    0.000686            32      0\n",
       "27306       0.231728          0.606135    0.014165            20      0\n",
       "117099      0.172651          0.639992    0.000275            26      0\n",
       "130878      0.216700          0.552614    0.000507            30      0\n",
       "45290       0.000000          0.640666    0.026498             9      0\n",
       "81422       0.500483          0.721759    0.184850            28      0\n",
       "150012      0.221304          0.795084    0.000228            46      0\n",
       "46046       0.238270          0.719227    0.000278            49      0\n",
       "186425      0.238324          0.668139    0.000270            46      0\n",
       "61459       0.192873          0.760512    0.199604            47      0\n",
       "\n",
       "[1604 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled.to_pickle('df_train_downsampled_features4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_headers2 = ['tfidf_cosine', 'count_vec_cosine', 'lda_cosine', 'common_words']\n",
    "target_header2 = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skamuf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(df_downsampled[feature_headers2], df_downsampled[target_header2],\n",
    "                                                        train_size=1603)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = pd.read_pickle(\"test_x_features4.pkl\")\n",
    "test_Y = pd.read_pickle(\"test_y_features4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skamuf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=0) \n",
    "forest.fit(train_x, train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7606843856249772\n",
      "F1 score: 0.02955129472227713\n",
      "Recall: 0.770618556701031\n",
      "Precision: 0.015064490124949616\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(test_Y, predictions))\n",
    "print('F1 score:', f1_score(test_Y, predictions))\n",
    "print('Recall:', recall_score(test_Y, predictions))\n",
    "print('Precision:', precision_score(test_Y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skamuf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "logistic_regression_model = LogisticRegression()\n",
    "trained_logistic_regression_model = logistic_regression_model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_prediction = trained_logistic_regression_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.793648472440561\n",
      "F1 score: 0.03289736706836484\n",
      "Recall: 0.7422680412371134\n",
      "Precision: 0.01682144734536534\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(test_Y, weighted_prediction))\n",
    "print('F1 score:', f1_score(test_Y, weighted_prediction))\n",
    "print('Recall:', recall_score(test_Y, weighted_prediction))\n",
    "print('Precision:', precision_score(test_Y, weighted_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skamuf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(train_x, train_y)\n",
    "svm_predictions = svm.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 4 features\n",
      "Accuracy: 0.7128895063308107\n",
      "F1 score: 0.024107364758512138\n",
      "Recall: 0.75\n",
      "Precision: 0.012250568325334681\n"
     ]
    }
   ],
   "source": [
    "print('SVM 4 features')\n",
    "print('Accuracy:', accuracy_score(test_Y, svm_predictions))\n",
    "print('F1 score:', f1_score(test_Y, svm_predictions))\n",
    "print('Recall:', recall_score(test_Y, svm_predictions))\n",
    "print('Precision:', precision_score(test_Y, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\skamuf\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(train_x, train_y)\n",
    "nb_predictions = naive_bayes.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 4 features\n",
      "Accuracy: 0.8517042615678962\n",
      "F1 score: 0.041282596706846295\n",
      "Recall: 0.6752577319587629\n",
      "Precision: 0.021292157659488012\n"
     ]
    }
   ],
   "source": [
    "print('Naive Bayes 4 features')\n",
    "print('Accuracy:', accuracy_score(test_Y, nb_predictions))\n",
    "print('F1 score:', f1_score(test_Y, nb_predictions))\n",
    "print('Recall:', recall_score(test_Y, nb_predictions))\n",
    "print('Precision:', precision_score(test_Y, nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
